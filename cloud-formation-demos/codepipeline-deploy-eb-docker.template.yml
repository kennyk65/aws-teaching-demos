AWSTemplateFormatVersion: 2010-09-09

# This is a  codepipeline demo that 
# 1) grabs code from GitHub on change 
# 2) packages and tests using parallel actions 
# 3) Docker-izes it, and stores in ECR
# 4) deploys it to ElasticBeanstalk

# TO RUN THIS:  You'll need a GitHub Repository, and a GitHub OAuthToken.
# To make a GitHub OAuthToken, go to GitHub / Settings / Personal Access Tokens
# The default value you see here will work only if you prepend it with a '0'.
# You will also need an ECR registry containing the image you want to deploy, at least the initial copy of it.  This will be updated by the pipeline.

Metadata:
  # Controlling the order of the parameters on the CloudFormation page;
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: The location of source code
        Parameters:
          - GitHubRepository
          - GitHubOAuthToken
      - Label:
          default: Docker Image
        Parameters:
          - DockerRepositoryPrefix
          - DockerImageName
      - Label:
          default: Other
        Parameters:
          - CodePipelineBucketPrefix

Parameters:
  GitHubRepository:
    Type: String
    Default:  kennyk65/aws-cloudbuild-demo/master
    Description:  The owner / repository / branch that you want to pull from.

  GitHubOAuthToken:
    Type: String
    Default:  b45b4b39fe35179592ceb5259c481b05a0eb27d
    Description:  CodePipeline sources require an OAuthToken, even if they are public.  To make one go to GitHub / Settings / Personal Access Tokens 

  DockerRepositoryPrefix:
    Description:  The name of the existing ECR repository, no image, no tag.  You'll have to create one and initially push to it the docker image that you want to demo.  CodeBuild will push an updated Docker image here when built.  Check that Region and account number.
    Type: String
    Default: 011673140073.dkr.ecr.us-west-2.amazonaws.com

  DockerImageName:
    Description:  The name of the docker container imaage, no tag suffixes.  
    Type: String
    Default:  spring-cloud-aws-environment-demo

  CodePipelineBucketPrefix:
    Description: CodePipeline needs a utility bucket for its internal use.  Specify the prefix for the bucket name.  You'll probably need to clean this out later to delete the stack.
    Type: String
    Default: codepipeline-kk-


Resources:

  # This Role allows CodeBuild to do certain things on our behalf.
  # See the policy for the interesting stuff:
  CodeBuildRole:
    Type: AWS::IAM::Role
    Properties: 
      RoleName: !Sub ${AWS::StackName}-CodeBuildRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement: 
          Effect: Allow
          Principal:
            Service: codebuild.amazonaws.com
          Action: sts:AssumeRole

  # This Policy is attached to the CodeBuildRole.
  # CodeBuild is get and put on S3, CodeBuild, and CloudWatch Logs.  Allowed to login and push to ECR.  This all could probably be tightened quite a bit.
  CodeBuildPolicy:
    Type: AWS::IAM::Policy
    Properties: 
      PolicyName: !Sub ${AWS::StackName}--CodeBuildPolicy
      PolicyDocument: 
        Version: 2012-10-17
        Statement: 
          Effect: Allow
          Action: 
            - logs:CreateLogGroup
            - logs:CreateLogStream
            - logs:PutLogEvents
            - s3:putObject
            - s3:getObject
            - codebuild:*
            - ecr:Get*                    # For Docker builds pushing to ECR, one will need to GetAuthorizationToken
            - ecr:InitiateLayerUpload     # For Docker push to ECR
            - ecr:Upload*                 # For Docker push to ECR
            - ecr:Complete*               # For Docker push to ECR
            - ecr:*                       # I'm getting weird results on Docker push, and this fixed it.  TODO - Figure out what ECR permissions are needed.
          Resource: "*"
      Roles: 
        -  !Ref CodeBuildRole

  # This Role allows CodePipeline to make certain things on our behalf:
  # See the policy for the interesting stuff:
  CodePipelineRole:
    Type: AWS::IAM::Role
    Properties: 
      RoleName: !Sub ${AWS::StackName}-CodePipelineRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement: 
          Effect: Allow
          Principal:
            Service: codepipeline.amazonaws.com
          Action: sts:AssumeRole

  # This Policy is attached to the CodePipelineRole.
  # CodePipeline is allowed carte blanche on S3, CodeBuild, and CloudWatch Logs; could probably be tightened quite a bit.
  CodePipelinePolicy:
    Type: AWS::IAM::Policy
    Properties: 
      PolicyName: !Sub ${AWS::StackName}-CodePipelinePolicy
      PolicyDocument: 
        Version: 2012-10-17
        Statement: 
          Effect: Allow
          # I can't quite determine which S3 permission CodePipeline wants.  The one-click policy grants everything...
          # codebuild probably does not need to be wide open like this, and the logs should only need
          # to create the stream, group, and log events.
          # Ultimately I ran into too many permission errors with little information available in the documentation to debug, so I had to use "*".
          Action: 
            # - logs:CreateLogGroup
            # - logs:CreateLogStream
            # - logs:PutLogEvents
            # - s3:putObject
            # - s3:getObject
            # - codebuild:*
            # - elasticbeanstalk:*
            - "*"                             #  TODO - FIND OUT WHAT CODE PIPELINE permissions are needed.
          Resource: 
            - "*"
      Roles: 
        -  !Ref CodePipelineRole

  # This Role is given to the ElasticBeanstalk environment:
  BeanstalkServiceRole:
    Type: AWS::IAM::Role
    Properties: 
      RoleName: !Sub ${AWS::StackName}-BeanstalkServiceRole  
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement: 
          Effect: Allow
          Principal:
            Service: elasticbeanstalk.amazonaws.com
          Action: sts:AssumeRole

  # This Policy is attached to the BeanstalkServiceRole.
  BeanstalkServicePolicy:
    Type: AWS::IAM::Policy
    Properties: 
      PolicyName: !Sub ${AWS::StackName}-BeanstalkServicePolicy
      PolicyDocument: 
        Version: 2012-10-17
        Statement: 
          Effect: Allow
          # I'm not sure exactly what permissions are needed here.  Docs are nearly impossible.
          Action: 
            - elasticbeanstalk:*
            - elasticloadbalancing:Describe*
            - ec2:Describe*
            - ec2:Get*
            - ec2:Associate*
            - logs:*
            - s3:*
            - autoscaling:*   
          Resource: 
            - "*"
      Roles: 
        -  !Ref BeanstalkServiceRole

  # This Role allows the EC2 Instance created by Elastic Beanstalk to make ECR calls.
  BeanstalkInstanceRole:
    Type: AWS::IAM::Role
    Properties: 
      RoleName: !Sub ${AWS::StackName}-BeanstalkInstanceRole  
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement: 
          Effect: Allow
          Principal:
            Service: ec2.amazonaws.com
          Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly


  # General Bucket where CodePipeline will store things:
  # Warning: This will need to be deleted manually before you can delete the stack.
  S3:
    Type: AWS::S3::Bucket
    Properties: 
      BucketName: !Sub ${CodePipelineBucketPrefix}-${AWS::Region}

  DockerBuild:
    Type: AWS::CodeBuild::Project
    Properties: 
      Name: !Sub ${AWS::StackName}-SoftwareBuild
      Description: Maven build, Docker image build + push to ECR
      ServiceRole: !Ref CodeBuildRole
      TimeoutInMinutes: 5
      Source:
        Type: CODEPIPELINE
        BuildSpec: !Sub |
            version: 0.2
            # This AWS CodeBuild buildspec runs a Maven build, packages as a Docker container, uploads to ECR.
            phases:
              install:
                runtime-versions:
                  java: corretto11  # formerly openjdk11             
              pre_build:
                commands:
                  - echo Version of AWS CLI is $(aws --version)
                  - echo Version of Docker is $(docker --version)
                  - echo Logging in to Amazon ECR...
                  - aws ecr get-login-password --region ${AWS::Region} | docker login --username AWS --password-stdin ${DockerRepositoryPrefix}
                  - REPOSITORY_URI=${DockerRepositoryPrefix}/${DockerImageName}
                  - IMAGE_TAG=$CODEBUILD_BUILD_NUMBER
                  - GIT_TAG=$CODEBUILD_RESOLVED_SOURCE_VERSION
                  - echo REPOSITORY_URI is set to $REPOSITORY_URI
                  - echo IMAGE_TAG is set to $IMAGE_TAG
                  - echo GIT_TAG is $GIT_TAG
              build:
                commands:
                  - mvn package -f pom-jar.xml
                  - docker build -t $REPOSITORY_URI .
                  - docker tag $REPOSITORY_URI:latest $REPOSITORY_URI:$IMAGE_TAG
                  - docker tag $REPOSITORY_URI:latest $REPOSITORY_URI:$GIT_TAG
                  - echo Docker Image Build finished on `date`
              post_build:
                commands:
                  - echo Pushing the Docker images...
                  - docker push $REPOSITORY_URI:latest
                  - docker push $REPOSITORY_URI:$IMAGE_TAG
                  - docker push $REPOSITORY_URI:$GIT_TAG
                  - echo Creating the Dockerrun.aws.json file needed by ElasticBeanstalk
                  - printf '{"AWSEBDockerrunVersion":"1","Image":{"Name":"%s"},"Ports":[{"ContainerPort":8080}]}' $REPOSITORY_URI:$IMAGE_TAG > Dockerrun.aws.json 
            artifacts:
                files: Dockerrun.aws.json                  
            #  This is implementing a "local / custom" cache to reduce maven download time on subsequent builds.
            #  See https://aws.amazon.com/about-aws/whats-new/2019/02/aws-codebuild-now-supports-local-caching/
            cache:
              paths:
                - '/root/.m2/**/*' 
                - '/root/var/lib/docker/**/*'                 
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/standard:5.0  
        PrivilegedMode: true
      Artifacts:    
        Type: CODEPIPELINE

  # This CodeBuild project runs unit tests only.  
  # The intent is to run parallel to the packaging to decrease build duration.
  MavenTests:
    Type: AWS::CodeBuild::Project
    Properties: 
      Name: !Sub ${AWS::StackName}-SoftwareTest
      Description: Demo of CodeBuild with CodeDeploy pipeline.
      ServiceRole: !Ref CodeBuildRole
      TimeoutInMinutes: 5
      Source:
        Type: CODEPIPELINE
        BuildSpec: !Sub |
            version: 0.2
            # This AWS CodeBuild buildspec runs the maven tests only.  No output.
            phases:
              install:
                runtime-versions:
                  java: corretto11  # formerly openjdk11 
              build:
                commands:
                  - mvn test
            cache:
              paths:
                - '/root/.m2/**/*' 
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/standard:5.0
      Artifacts:    
        Type: CODEPIPELINE


  # This is the CodePipeline with its stages:
  MyPipe:
    Type: AWS::CodePipeline::Pipeline
    Properties:
      Name: !Sub ${AWS::StackName}-PipeFromGitHubToEB
      ArtifactStore: 
        Location: !Ref S3
        Type: S3
      RestartExecutionOnUpdate: true
      RoleArn: !GetAtt CodePipelineRole.Arn
      Stages: 

        # Stage 1:  Get the source from GitHub:
        - Name: Source
          Actions: 
            - Name: SourceAction
              RunOrder: 1
              ActionTypeId: 
                Category: Source
                Owner: ThirdParty       
                Provider: GitHub        
                Version: 1              # Required, meaningless and must be 1, go figure.
              Configuration: 
                Owner: !Select [0, !Split [ "/" , !Ref GitHubRepository ]]
                Repo: !Select [1, !Split [ "/" , !Ref GitHubRepository ]]
                Branch: !Select [2, !Split [ "/" , !Ref GitHubRepository ]]
                PollForSourceChanges: true   # Don't know if/how to control frequency
                OAuthToken: !Ref GitHubOAuthToken     # Public repository, Don't know why AWS needs this
              OutputArtifacts: 
                - Name: TheSourceCode

        # Stage 2:  Build using CodeBuild / Maven, Test in parallel using CodeBuild / Maven:
        - Name: Build
          Actions:
            # This runs a Maven build which packages the WAR.  Test are run in the parallel action below: 
            - Name: DockerBuild
              RunOrder: 1
              InputArtifacts: 
                - Name: TheSourceCode           # Duh, the output from the previous step.
              ActionTypeId: 
                Category: Build
                Owner: AWS       
                Provider: CodeBuild        
                Version: 1                      # Required, meaningless and must be 1.
              Configuration:
                ProjectName:  !Ref DockerBuild   # See the CodeBuild definition above.       
              OutputArtifacts: 
                - Name: TheDockerrunAwsJson 

            # This runs a Maven build featuring only the unit tests.  No output:   
            - Name: UnitTest
              RunOrder: 1
              InputArtifacts: 
                - Name: TheSourceCode       
              ActionTypeId: 
                Category: Build
                Owner: AWS       
                Provider: CodeBuild        
                Version: 1                  
              Configuration:
                ProjectName:  !Ref MavenTests  # See the CodeBuild definition above.       

        # Stage 3:  Deploy on ElasticBeanstalk:
        - Name: Deploy
          Actions:
            # This Deploys on ElasticBeanstalk so we can quickly smoke-test the running app: 
            - Name: Deploy
              RunOrder: 1
              InputArtifacts: 
                - Name: TheDockerrunAwsJson         # Duh, the output from the previous step.
              ActionTypeId: 
                Category: Deploy
                Owner: AWS       
                Provider: ElasticBeanstalk        
                Version: 1                  # Don't know the purpose of 'version'
              Configuration:
                ApplicationName:  !Ref BeanstalkApplication  # See the EB definition below.       
                EnvironmentName:  !Ref BeanstalkEnvironment  # See the EB definition below.       
 

  BeanstalkApplication:
    Type: AWS::ElasticBeanstalk::Application
    Properties:
      ApplicationName: !Sub ${AWS::StackName}-TestApplication
      Description: Quick live-test environment for the app.

  BeanstalkEnvironment:
    Type: AWS::ElasticBeanstalk::Environment
    Properties:
      ApplicationName: !Ref BeanstalkApplication
      EnvironmentName: TestEnvironment
      Description: Quick live-test environment for the app.
      CNAMEPrefix: !Sub ${DockerImageName}    # This will become part of the DNS name.
      SolutionStackName: "64bit Amazon Linux 2018.03 v2.16.7 running Docker 19.03.13-ce"
      OptionSettings: 
      - Namespace: aws:elasticbeanstalk:application
        OptionName: "Application Healthcheck URL"
        Value: /actuator/health

      - Namespace: aws:elasticbeanstalk:environment
        OptionName: ServiceRole
        Value: !Ref BeanstalkServiceRole

      - Namespace: aws:autoscaling:launchconfiguration
        OptionName: IamInstanceProfile
        Value: !Ref EBInstanceProfile

  EBInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties: 
      InstanceProfileName: !Sub ${AWS::StackName}-InstanceProfile
      Roles: [!Ref BeanstalkInstanceRole ]

  # This custom resource calls our Lambda function:
  CustomResourceBucketCleaner:
    Type: Custom::bucketCleaner
    Properties:
      ServiceToken: !GetAtt CustomResourceBucketCleanerLambda.Arn
      destinationBucket: !Ref S3

  # This function will cleanup the S3 bucket before delete.
  CustomResourceBucketCleanerLambda:
    Type: AWS::Lambda::Function
    DependsOn: CloudwatchLogsGroupBucketCleaner
    Properties: 
      FunctionName: !Sub ${AWS::StackName}-BucketCleanerCustomResource
      Description: Cleans out the S3 bucket on stack delete
      Role: !GetAtt CustomResourceRole.Arn
      MemorySize: 128     
      Timeout: 10         
      Runtime: python3.8
      Handler: index.lambda_handler
      Code:
        ZipFile: !Sub |
          import cfnresponse
          import boto3

          # Entry point:
          def lambda_handler(event, context):
              # Get the CloudFormation request type
              requestType = event['RequestType']
              destinationBucket = event['ResourceProperties']['destinationBucket']

              responseData = {}
              s3 = boto3.client('s3')

              if requestType == 'Delete':
                print ('Clean out bucket to enable delete... ' )
                boto3.resource('s3').Bucket(destinationBucket).objects.all().delete()

              # Unless something blew up, we should wander into this code:
              cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)

  # This Role gives permission to our custom resource Lambda.
  CustomResourceRole:
    Type: AWS::IAM::Role
    Properties: 
      RoleName: !Sub ${AWS::StackName}-CustomResourceRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement: 
          Effect: Allow
          Principal:
            Service: lambda.amazonaws.com
          Action: sts:AssumeRole
      Policies:
      - PolicyName: !Sub ${AWS::StackName}-CustomResourcePolicy
        PolicyDocument: 
          Version: 2012-10-17
          Statement: 
            Effect: Allow
            Action: 
              - logs:CreateLogGroup
              - logs:CreateLogStream
              - logs:PutLogEvents
              - s3:List*
              - s3:Delete*
            Resource: "*"


  # CloudWatch Logs Groups are created automatically when CodeBuild or Lambda writes output,
  # but they are easier to cleanup when they are part of the stack.  
  CloudwatchLogsGroupBuild:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub /aws/codebuild/${AWS::StackName}-SoftwareBuild
      RetentionInDays: 3

  CloudwatchLogsGroupTest:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub /aws/codebuild/${AWS::StackName}-SoftwareTest
      RetentionInDays: 3

  CloudwatchLogsGroupBucketCleaner:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub /aws/lambda/${AWS::StackName}-BucketCleanerCustomResource
      RetentionInDays: 3


Outputs:
  WebsiteURL:
    Value: !Sub http://${BeanstalkEnvironment.EndpointURL} 


