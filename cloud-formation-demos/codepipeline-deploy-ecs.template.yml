AWSTemplateFormatVersion: 2010-09-09

# This is a  codepipeline demo that 
# 1) grabs code from GitHub on change 
# 2) creates a docker image and runs tests using paralell actions 
# 3) Stores in the image in ECR
# 4) deploy to an ECS Cluster with your choice of FARGATE or EC2 backed deployment

# TO RUN THIS:  You'll need a GitHub Repository, and a GitHub OAuthToken.
# To make a GitHub OAuthToken, go to GitHub / Settings / Personal Access Tokens
# The default value you see here will work only if you prepend it with a '0'.
# You will also need a working ECS Cluster.  "Default" is fine for Fargate, or create one with "base-ecs-cluster.template.yml".
# You will also need a private ECR registry for storing the image you want to deploy.  The pipeline will build the image and upload it to this registry.
#  This article helped immensely:  https://www.prodops.io/blog/deploying-fargate-services-using-cloudformation

Metadata:
  # Controlling the order of the parameters on the CloudFormation page;
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: The location of source code
        Parameters:
          - GitHubRepository
          - GitHubOAuthToken
      - Label:
          default: Target ECS Cluster
        Parameters:
          - DockerRepositoryPrefix
          - DockerImage
          - ContainerPort
          - ECSCluster
          - ClusterType
      - Label:
          default: Other
        Parameters:
          - CodePipelineBucketPrefix
          - VpcId
          - SubnetIds

Parameters:
  GitHubRepository:
    Type: String
    Default:  kennyk65/aws-cloudbuild-demo/master
    Description:  The owner / repository / branch that you want to pull from.

  GitHubOAuthToken:
    Type: String
    Default:  b45b4b39fe35179592ceb5259c481b05a0eb27d
    Description:  CodePipeline sources require an OAuthToken, even if they are public.  To make one go to GitHub / Settings / Personal Access Tokens 

  ECSCluster:
    Description:  The ECS Cluster that is ready to run our service / task definition.
    Type: String    
    Default: default

  DockerRepositoryPrefix:
    Description:  The prefix of the existing private ECR repository.  You'll have to create one and initially push to it the docker image that you want to demo.  CodeBuild will push an updated Docker image here when built.  Check that Region and account number.
    Type: String
    Default: 011673140073.dkr.ecr.us-west-2.amazonaws.com

  DockerImage:
    Description:  The docker image name, no prefix, no tag. You'll have to create one and initially push to it the docker image that you want to demo.  CodeBuild will push an updated Docker image here when built.  Check that Region and account number.
    Type: String
    Default: spring-cloud-aws-environment-demo

  ContainerPort:
    Type: String
    Default: 80
    Description: The port that the Docker container will listen on.  For example nginx would listen on port 80, mysql would expect 3306, etc.
    
  ClusterType:
    Description:  Do you want to deploy to a standard ECS cluster or Fargate cluster?  Fargate is easier, but more expensive.
    Type: String
    Default: Fargate
    AllowedValues:
      - ECS
      - Fargate

  CodePipelineBucketPrefix:
    Description: CodePipeline needs a utility bucket for its internal use.  Specify the prefix for the bucket name.  You'll probably need to clean this out later to delete the stack.
    Type: String
    Default: codepipeline-kk-

  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: Select the VPC that you want to access the running containers through.

  SubnetIds:
    Type: List<AWS::EC2::Subnet::Id>
    Description: Select 1-2 public subnets in your VPC where you want the resulting containers to be accessible from.


Conditions:
  DeployToFargate:     !Equals [ !Ref ClusterType, Fargate ]
  DeployToEc2:  !Not [ !Equals [ !Ref ClusterType, Fargate ] ]


Resources:

  # This Role allows CodeBuild to do certain things on our behalf.
  # See the policy for the interesting stuff:
  CodeBuildRole:
    Type: AWS::IAM::Role
    Properties: 
      RoleName: !Sub ${AWS::StackName}-CodeBuildRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement: 
          Effect: Allow
          Principal:
            Service: codebuild.amazonaws.com
          Action: sts:AssumeRole
      Policies:
      - PolicyName: !Sub ${AWS::StackName}-CodeBuildPolicy
        PolicyDocument: 
          Version: 2012-10-17
          Statement: 
            Effect: Allow
            Action: 
              - logs:CreateLogGroup
              - logs:CreateLogStream
              - logs:PutLogEvents
              - s3:putObject
              - s3:getObject
              - codebuild:*
              - ecr:Get*                    # For Docker builds pushing to ECR, one will need to GetAuthorizationToken
              - ecr:InitiateLayerUpload     # For Docker push to ECR
              - ecr:Upload*                 # For Docker push to ECR
              - ecr:Complete*               # For Docker push to ECR
              - ecr:*                       # I'm getting weird results on Docker push, and this fixed it.  TODO - Figure out what ECR permissions are needed.
            Resource: "*"

  # This Role allows CodePipeline to make certain things on our behalf:
  # See the policy for the interesting stuff:
  CodePipelineRole:
    Type: AWS::IAM::Role
    Properties: 
      RoleName: !Sub ${AWS::StackName}-CodePipelineRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement: 
          Effect: Allow
          Principal:
            Service: codepipeline.amazonaws.com
          Action: sts:AssumeRole
      Policies:
      - PolicyName: !Sub ${AWS::StackName}-CodePipelinePolicy
        PolicyDocument: 
          Version: 2012-10-17
          Statement: 
            Effect: Allow
            # I can't quite determine which S3 permission CodePipeline wants.  The one-click policy grants everything...
            # codebuild probably does not need to be wide open like this, and the logs should only need
            # to create the stream, group, and log events.
            # Ultimately I ran into too many permission errors with little information available in the documentation to debug, so I had to use "*".
            Action: 
              # - logs:CreateLogGroup
              # - logs:CreateLogStream
              # - logs:PutLogEvents
              # - s3:putObject
              # - s3:getObject
              # - codebuild:*
              # - elasticbeanstalk:*
              - "*"                             #  TODO - FIND OUT WHAT CODE PIPELINE permissions are needed.
            Resource: 
              - "*"

  # The IAM Role to be used by the ECS Service.  Not the tasks, not the EC2 instances, etc..
  # Essential permissions to allow registration / deregistration with load balancer.
  ECSServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Effect: Allow
          Action: sts:AssumeRole
          Principal:
            Service: ecs.amazonaws.com
      Policies:
      - PolicyName: ecs-service
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action: 
              - elasticloadbalancing:Register*
              - elasticloadbalancing:Deregister*
              - elasticloadbalancing:Describe*
              - ec2:Describe*
              - ec2:AuthorizeSecurityGroupIngress
            Resource: '*'

  # When running in Fargate, the task definition MUST have a role
  # providing "to support log driver awslogs", whatever that is.
  # It also needs permission to pull images from ECR:
  EcsTaskRole:
    Type: AWS::IAM::Role
    Properties: 
      RoleName: !Sub ${AWS::StackName}-EcsTaskRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement: 
          Effect: Allow
          Principal:
            Service: ecs-tasks.amazonaws.com
          Action: sts:AssumeRole
      Policies:
      - PolicyName: !Sub ${AWS::StackName}-EcsTaskPolicy
        PolicyDocument: 
          Version: 2012-10-17
          Statement: 
            Effect: Allow
            Action: 
              - logs:*    #  Not sure which permissions are needed for some kind of logging activity.
              - ecr:*     #  Not sure which permissions are needed to pull an ECR image.
            Resource: 
              - "*"

  # General Bucket where CodePipeline will store things:
  # Warning: This will need to be deleted manually before you can delete the stack.
  S3:
    Type: AWS::S3::Bucket
    Properties: 
      BucketName: !Sub ${CodePipelineBucketPrefix}${AWS::Region}

  # Security Group for the ECS containers when running in Fargate mode:
  EcsContainerSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub ${AWS::StackName}-EcsSecurityGroup
      GroupDescription: ECS Security Group
      VpcId: !Ref VpcId
      #  Inbound rules for HTTP on 80 and 8080:
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: 80
        ToPort: 80
        CidrIp: 0.0.0.0/0
      - IpProtocol: tcp
        FromPort: !Ref ContainerPort
        ToPort: !Ref ContainerPort
        CidrIp: 0.0.0.0/0


  # This CodeBuild project runs packaging, tests are separate.
  # This is a Java / Maven build, Followed by Dockerization / push to ECR
  DockerBuild:
    Type: AWS::CodeBuild::Project
    Properties: 
      Name: !Sub ${AWS::StackName}-SoftwareBuild
      Description: Maven build, Docker image build + push to ECR
      ServiceRole: !Ref CodeBuildRole
      TimeoutInMinutes: 5
      Source:
        Type: CODEPIPELINE
        BuildSpec: !Sub |
            version: 0.2
            # This AWS CodeBuild buildspec runs a Maven build, packages as a Docker container, uploads to ECR.
            phases:
              install:
                runtime-versions:
                  java: corretto11  # formerly openjdk11             
              pre_build:
                commands:
                  - echo Version of AWS CLI is $(aws --version)
                  - echo Version of Docker is $(docker --version)
                  - echo Logging in to Amazon ECR...
                  - aws ecr get-login-password --region ${AWS::Region} | docker login --username AWS --password-stdin ${DockerRepositoryPrefix}
                  - REPOSITORY_URI=${DockerRepositoryPrefix}/${DockerImage}
                  - IMAGE_TAG=$CODEBUILD_BUILD_NUMBER
                  - GIT_TAG=$CODEBUILD_RESOLVED_SOURCE_VERSION
                  - echo REPOSITORY_URI is set to $REPOSITORY_URI
                  - echo IMAGE_TAG is set to $IMAGE_TAG
                  - echo GIT_TAG is $GIT_TAG
              build:
                commands:
                  - mvn package -f pom-jar.xml
                  - docker build -t $REPOSITORY_URI .
                  - docker tag $REPOSITORY_URI:latest $REPOSITORY_URI:$IMAGE_TAG
                  - docker tag $REPOSITORY_URI:latest $REPOSITORY_URI:$GIT_TAG
                  - echo Docker Image Build finished on `date`
              post_build:
                commands:
                  - echo Pushing the Docker images...
                  - docker push $REPOSITORY_URI:latest
                  - docker push $REPOSITORY_URI:$IMAGE_TAG
                  - docker push $REPOSITORY_URI:$GIT_TAG
                  - echo Writing image definitions file...
                  - printf '[{"name":"TheContainer","imageUri":"%s"}]' $REPOSITORY_URI:$IMAGE_TAG > imagedefinitions.json
            artifacts:
                files: imagedefinitions.json
            #  This is implementing a "local / custom" cache to reduce maven download time on subsequent builds.
            #  See https://aws.amazon.com/about-aws/whats-new/2019/02/aws-codebuild-now-supports-local-caching/
            cache:
              paths:
                - '/root/.m2/**/*' 
                - '/root/var/lib/docker/**/*'                 
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/standard:5.0  
        PrivilegedMode: true
      Artifacts:    
        Type: CODEPIPELINE


  # This CodeBuild project runs unit tests only.  
  # The intent is to run parallel to the packaging to decrease build duration.
  MavenTests:
    Type: AWS::CodeBuild::Project
    Properties: 
      Name: !Sub ${AWS::StackName}-MavenTests
      Description: Demo of CodeBuild with CodeDeploy pipeline.
      ServiceRole: !Ref CodeBuildRole
      TimeoutInMinutes: 5
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/standard:5.0  
      Source:
        Type: CODEPIPELINE
        BuildSpec: !Sub |
            version: 0.2
            # This AWS CodeBuild buildspec runs the maven tests only.  No output.
            phases:
              install:
                runtime-versions:
                  java: corretto11  # formerly openjdk11 
              build:
                commands:
                  -  mvn -f pom-jar.xml package 
      Artifacts:    
        Type: CODEPIPELINE


  # This is the CodePipeline with its stages:
  MyPipe:
    Type: AWS::CodePipeline::Pipeline
    Properties:
      Name: !Sub ${AWS::StackName}-PipeFromGitHubToECS
      ArtifactStore: 
        Location: !Ref S3
        Type: S3
      RestartExecutionOnUpdate: true
      RoleArn: !GetAtt CodePipelineRole.Arn
      Stages: 

        # Stage 1:  Get the source from GitHub:
        - Name: Source
          Actions: 
            - Name: SourceAction
              RunOrder: 1
              ActionTypeId: 
                Category: Source
                Owner: ThirdParty       
                Provider: GitHub        
                Version: 1              # Required, meaningless and must be 1, go figure.
              Configuration: 
                Owner: !Select [0, !Split [ "/" , !Ref GitHubRepository ]]
                Repo: !Select [1, !Split [ "/" , !Ref GitHubRepository ]]
                Branch: !Select [2, !Split [ "/" , !Ref GitHubRepository ]]
                PollForSourceChanges: true   # Don't know if/how to control frequency
                OAuthToken: !Ref GitHubOAuthToken     # Public repository, Don't know why AWS needs this
              OutputArtifacts: 
                - Name: TheSourceCode

        # Stage 2:  Build using CodeBuild / Maven, Test in parallel using CodeBuild / Maven:
        - Name: Build
          Actions:
            # This runs a Maven build which packages the WAR.  Test are run in the parallel action below: 
            - Name: DockerBuild
              RunOrder: 1
              InputArtifacts: 
                - Name: TheSourceCode           # Duh, the output from the previous step.
              ActionTypeId: 
                Category: Build
                Owner: AWS       
                Provider: CodeBuild        
                Version: 1                      # Required, meaningless and must be 1.
              Configuration:
                ProjectName:  !Ref DockerBuild   # See the CodeBuild definition above.       
              OutputArtifacts: 
                - Name: TheImageDefinition 

            # This runs a Maven build featuring only the unit tests.  No output:   
            - Name: UnitTest
              RunOrder: 1
              InputArtifacts: 
                - Name: TheSourceCode       
              ActionTypeId: 
                Category: Build
                Owner: AWS       
                Provider: CodeBuild        
                Version: 1                  
              Configuration:
                ProjectName:  !Ref MavenTests  # See the CodeBuild definition above.       

        # Stage 3:  Deploy on ECS:
        - Name: Deploy
          Actions:
            - Name: Deploy
              RunOrder: 1
              InputArtifacts: 
                - Name: TheImageDefinition   # This should contain imagedefinitions.json
              ActionTypeId: 
                Category: Deploy
                Owner: AWS       
                Provider: ECS        
                Version: 1                  # Don't know the purpose of 'version'
              Configuration:
                ClusterName:  !Ref ECSCluster  # Input parameter       
                ServiceName:  !Sub ${AWS::StackName}-service
 
  # An ECS "Service" associates a TaskDefinition with a cluster; it ties tasks to load balancers. 
  # The settings are significantly different for Fargate vs normal EC2-backed Cluster, hence two separate definitions.
  # EC2 requires role setting, but Fargate must not have this.  Fargate requires network configuration, generally not needed for EC2.
  ECSServiceEc2:
    Type: AWS::ECS::Service
    Condition: DeployToEc2
    DependsOn: ALBListener   # Problematic to create service before load balancer in place.
    Properties:
      ServiceName: !Sub ${AWS::StackName}-service
      Cluster: !Ref ECSCluster
      Role: !Ref ECSServiceRole
      TaskDefinition: !Ref TaskDefinitionEc2
      DesiredCount: 1
      LoadBalancers:        
      - ContainerName: TheContainer  # The name of the container cannot be a reasonable value like the image name.
        ContainerPort: !Ref ContainerPort
        TargetGroupArn: !Ref ALBTargetGroup

  ECSServiceFargate:
    Type: AWS::ECS::Service
    Condition: DeployToFargate
    DependsOn: ALBListener  # Problematic to create service before cluster nodes or load balancer in place.
    Properties:
      ServiceName: !Sub ${AWS::StackName}-service
      Cluster: !Ref ECSCluster
      LaunchType: FARGATE
      TaskDefinition: !Ref TaskDefinitionFargate
      DesiredCount: 1
      LoadBalancers:        
      - ContainerName: TheContainer  # The name of the container cannot be a reasonable value like the image name.
        ContainerPort: !Ref ContainerPort
        TargetGroupArn: !Ref ALBTargetGroup
      NetworkConfiguration: 
        AwsvpcConfiguration:
          AssignPublicIp: ENABLED
          SecurityGroups: 
            - !Ref EcsContainerSecurityGroup
          Subnets: !Ref SubnetIds


  # This TaskDefinition defines the image(s) we want to run on ECS
  TaskDefinitionEc2:
    Type: AWS::ECS::TaskDefinition
    Condition: DeployToEc2
    Properties:
      Family: !Sub ${AWS::StackName}-ecs-demo-app
      ContainerDefinitions:
      - Name: TheContainer    # The name of the container cannot be a reasonable value like the image name.
        Image: nginx:latest   # pre-seeded image used to temporarily establish the task/service before the first build replaces it. 
        Cpu: 256        # 256 CPU units is 1/4 of a vCPU                   
        Memory: 512                            
        Essential: true
        LogConfiguration:
          LogDriver: awslogs
          Options:
            awslogs-group: !Ref CloudwatchLogsGroup
            awslogs-region: !Ref AWS::Region
            awslogs-stream-prefix: ecs-demo-app
        PortMappings:
        - ContainerPort: !Ref ContainerPort
          # Notice how the HostPort is not defined.  This means it will be assigned randomly.  The ALB will find it automatically.  Cool huh?

  # This TaskDefinition defines the image(s) we want to run on ECS
  TaskDefinitionFargate:
    Type: AWS::ECS::TaskDefinition
    Condition: DeployToFargate
    Properties:
      Family: !Sub ${AWS::StackName}-ecs-demo-app
      ExecutionRoleArn: !GetAtt EcsTaskRole.Arn    # Required in Fargate, optional otherwise
      Cpu: 1024                                 # Task-level setting required in Fargate, plus it seems to require more memory. 
      Memory: 2GB                            # Task-level setting required in Fargate, plus it seems to require more memory.
      NetworkMode: awsvpc                 # Required for Fargate, ironic because this is the only option in Fargate.
      RequiresCompatibilities:  
      - FARGATE  # Must be Fargate on Fargate
      ContainerDefinitions:
      - Name: TheContainer    # The name of the container cannot be a reasonable value like the image name.
        Image: nginx:latest   # pre-seeded image used to temporarily establish the task/service before the first build replaces it. 
        Essential: true
        LogConfiguration:
          LogDriver: awslogs
          Options:
            awslogs-group: !Ref CloudwatchLogsGroup
            awslogs-region: !Ref AWS::Region
            awslogs-stream-prefix: ecs-demo-app
        PortMappings:
        - ContainerPort: !Ref ContainerPort
          # Notice how the HostPort is not defined.  This means it will be assigned randomly.  The ALB will find it automatically.  Cool huh?
        

  # Now the Load Balancer, with all of its sub-components:
  ALB:
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: !Sub ${AWS::StackName}-ALB
      Scheme: internet-facing
      Subnets: !Ref SubnetIds
      SecurityGroups: [!Ref EcsContainerSecurityGroup]
  # Listen on port 80, pass all traffic to our only TargetGroup:
  ALBListener:
    Type: AWS::ElasticLoadBalancingV2::Listener
    # DependsOn: ECSServiceRole
    Properties:
      Port: 80
      Protocol: HTTP
      LoadBalancerArn: !Ref ALB
      DefaultActions:
      - Type: forward
        TargetGroupArn: !Ref ALBTargetGroup
  # This TargetGroup is hooked up to the ECS "Service" above.
  ALBTargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      #Name: !Sub ${AWS::StackName}-ALBTargetGroup
      VpcId: !Ref VpcId
      TargetType: !If [DeployToFargate, ip, instance]  # Fargate deploy must be IP for awsvpc mode, otherwise instance.
      Port: !Ref ContainerPort
      Protocol: HTTP
      HealthCheckProtocol: HTTP
      HealthCheckPath: /   
      HealthCheckIntervalSeconds: 15
      HealthCheckTimeoutSeconds: 10
      HealthyThresholdCount: 2
      UnhealthyThresholdCount: 3

  # This custom resource calls our Lambda function:
  CustomResourceBucketCleaner:
    Type: Custom::bucketCleaner
    Properties:
      ServiceToken: !GetAtt CustomResourceBucketCleanerLambda.Arn
      destinationBucket: !Ref S3

  # This function will cleanup the S3 bucket before delete.
  CustomResourceBucketCleanerLambda:
    Type: AWS::Lambda::Function
    DependsOn: CloudwatchLogsGroupBucketCleaner
    Properties: 
      FunctionName: !Sub ${AWS::StackName}-BucketCleanerCustomResource
      Description: Cleans out the S3 bucket on stack delete
      Role: !GetAtt CustomResourceRole.Arn
      MemorySize: 128     
      Timeout: 10         
      Runtime: python3.8
      Handler: index.lambda_handler
      Code:
        ZipFile: !Sub |
          import cfnresponse
          import boto3

          # Entry point:
          def lambda_handler(event, context):
              # Get the CloudFormation request type
              requestType = event['RequestType']
              destinationBucket = event['ResourceProperties']['destinationBucket']

              responseData = {}
              s3 = boto3.client('s3')

              if requestType == 'Delete':
                print ('Clean out bucket to enable delete... ' )
                boto3.resource('s3').Bucket(destinationBucket).objects.all().delete()

              # Unless something blew up, we should wander into this code:
              cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)

  # This Role gives permission to our custom resource Lambda.
  CustomResourceRole:
    Type: AWS::IAM::Role
    Properties: 
      RoleName: !Sub ${AWS::StackName}-CustomResourceRole
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement: 
          Effect: Allow
          Principal:
            Service: lambda.amazonaws.com
          Action: sts:AssumeRole
      Policies:
      - PolicyName: !Sub ${AWS::StackName}-CustomResourcePolicy
        PolicyDocument: 
          Version: 2012-10-17
          Statement: 
            Effect: Allow
            Action: 
              - logs:CreateLogGroup
              - logs:CreateLogStream
              - logs:PutLogEvents
              - s3:List*
              - s3:Delete*
            Resource: "*"

  # CloudWatch Logs Groups are created automatically when CodeBuild or Lambda writes output,
  # but they are easier to cleanup when they are part of the stack.  
  CloudwatchLogsGroupBuild:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub /aws/codebuild/${AWS::StackName}-MyBuild
      RetentionInDays: 3

  CloudwatchLogsGroupTest:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub /aws/codebuild/${AWS::StackName}-MyTest
      RetentionInDays: 3

  CloudwatchLogsGroupBucketCleaner:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub /aws/lambda/${AWS::StackName}-BucketCleanerCustomResource
      RetentionInDays: 3

  CloudwatchLogsGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub ${AWS::StackName}-SpringEnvironmentDemoECSLogGroup
      RetentionInDays: 3

Outputs:
  ECSALB:
    Description: Your ALB DNS URL
    Value: !Sub http://${ALB.DNSName}
