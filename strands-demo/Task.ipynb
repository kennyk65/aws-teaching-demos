{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc40c48b-0c95-4757-a067-563cfccd51a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Task 2: Build your first AI agent\n",
    "\n",
    "In this notebook, you learn how to build AI agents using the Strands Agents framework. You start by creating a conversational agent, then add tools to make it more capable. You finally build a practical recipe assistant that can search the web for cooking information. You use Amazon Bedrock with the Amazon Nova Lite model to power your agents.\n",
    "\n",
    "AI agents differ from traditional LLMs because they can take actions, use tools, and work toward goals autonomously. Rather than only responding to questions, agents can actually do things for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a413e2-3c34-4073-9000-d8556537bb6a",
   "metadata": {},
   "source": [
    "#### Scenario\n",
    "You work for AnyCompany, a growing technology company that wants to explore how AI agents can help automate everyday tasks. Your team is interested in learning how these agents could help with tasks like research and customer support. You are starting with the basics of building intelligent agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazon-q-note",
   "metadata": {},
   "source": [
    "<i aria-hidden=\"true\" class=\"fas fa-info-circle\" style=\"color:#007FAA\"></i> **Learn more:** As you work through this notebook, you can use Amazon Q Developer to help understand the Python code and logic. Amazon Q can explain code snippets, suggest improvements, and help you learn Python programming concepts.\n",
    "\n",
    "**To access Amazon Q Developer in JupyterLab:**\n",
    "\n",
    "<!-- ![Amazon Q location in JupyterLab](./images/amazon-q-location.png) -->\n",
    "<img src=\"images/amazon-q-location.png\" width=50% height=20% />\n",
    "\n",
    "*Image description: The preceding screenshot shows the JupyterLab interface with the Amazon Q panel visible in the left sidebar. The Amazon Q icon and chat interface are highlighted, showing where students can access Amazon Q Developer features.*\n",
    "\n",
    "1. Look for the **Amazon Q** panel in the left sidebar of your JupyterLab interface (as shown in the image above)\n",
    "2. Once connected, you can:\n",
    "   - Select a code block cell, right-click, and choose **Generative AI** > **Explain code**.\n",
    "   - Type questions about Python syntax, functions, or programming concepts in the Amazon Q chat.\n",
    "   - Ask for code suggestions or improvements.\n",
    "   - Get help with debugging errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2797f9",
   "metadata": {},
   "source": [
    "## Task 2.1: Environment setup\n",
    "\n",
    "In this task, you set up your environment by installing the necessary packages to get started with building AI agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776fd083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install the Strands Agents framework and tools\n",
    "%pip install strands-agents strands-agents-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f634211-3de1-4390-8c3f-367af5554c39",
   "metadata": {},
   "source": [
    "## Task 2.2: Create your first AI agent\n",
    "\n",
    "In this task, you create an AI agent that can have conversations. This agent uses Amazon Bedrock with the Amazon Nova Lite model to understand and respond to your messages. The system prompt defines the desired behavior of your agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45ee2bae-6415-4dba-af98-a19028305c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 15:00:30,175 | INFO | botocore.credentials | Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=r\"datetime.datetime.utcnow\") \n",
    "\n",
    "from strands import Agent\n",
    "\n",
    "# Create your first AI agent\n",
    "agent = Agent(callback_handler=None,\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    system_prompt=\"You are a helpful assistant that provides concise responses.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1a37c",
   "metadata": {},
   "source": [
    "Next, you test your agent by sending it a message.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Note:** The Strands framework uses Amazon Bedrock with the Amazon Nova Lite model by default. This model supports conversational interactions and can be enhanced with tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8af670eb-ad02-40df-a19c-3ed835fac8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Send a message to the agent\n",
    "response = agent(\"Hello! Tell me a joke.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088cf6bf-dd73-4710-a0cc-6c11d220c431",
   "metadata": {},
   "source": [
    "## Task 2.3: Add tools to your agent\n",
    "\n",
    "In this task, you give your agent tools so it can do more than chat.\n",
    "\n",
    "- You add a calculator tool which is provided by the Strands Agents SDK.\n",
    "\n",
    "- You create a weather tool using the @tool decorator. \n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Note:** The weather tool is a placeholder example and will always return ‘Sunny’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent, tool\n",
    "from strands_tools import calculator\n",
    "\n",
    "# Create a weather tool\n",
    "@tool\n",
    "def weather():\n",
    "    \"\"\"Get current weather information\"\"\"\n",
    "    return \"Sunny and O degree Celsius\"\n",
    "\n",
    "# Create an agent with tools\n",
    "agent_with_tools = Agent(callback_handler=None,\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    tools=[calculator, weather],\n",
    "    system_prompt=\"You are a helpful assistant. You can do math calculations and use the weather tool to tell the weather.\"\n",
    ")\n",
    "\n",
    "# Test the agent with both tools in one query\n",
    "# Note: This query requires both tools - the weather tool to get temperature in Celsius,\n",
    "# and the calculator tool to convert from Celsius to Fahrenheit.\n",
    "# The agent will automatically determine which tools to use and in what order.\n",
    "response = agent_with_tools(\"What is the weather in Seattle in Fahrenheit?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "calculator-demo-md",
   "metadata": {},
   "source": [
    "Now explore how the agent analyze the question and decide to use only the calculator tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculator-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a math question that only needs the calculator tool\n",
    "# The agent will analyze the question and decide to use only the calculator tool\n",
    "math_query = \"What is 25 * 4 + 18?\"\n",
    "print(\"=== Agent Chooses Calculator Tool ===\")\n",
    "print(f\"Query: {math_query}\")\n",
    "response = agent_with_tools(math_query)\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379498f2",
   "metadata": {},
   "source": [
    "### Direct Tool Invocation\n",
    "\n",
    "You can also call tools directly without going through the agent conversation. This is useful for testing or when you want to use a specific tool function.\n",
    "\n",
    "**Specification for direct tool invocation:**\n",
    "- Use `agent.tool.tool_name()` to call a specific tool directly\n",
    "- Pass the required parameters as function arguments\n",
    "- This bypasses the agent's natural language processing and tool selection logic\n",
    "- Useful for programmatic access to tool functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the calculator tool directly\n",
    "# Note: Direct tool invocation bypasses the agent's conversation flow.\n",
    "# Use agent_with_tools.tool.calculator() to call the calculator tool directly\n",
    "# without the agent deciding which tool to use. This is useful for testing\n",
    "# specific tools or when you know exactly which tool function you need.\n",
    "result = agent_with_tools.tool.calculator(expression=\"2 + 3 * 4\")\n",
    "print(f\"Calculator result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca6751",
   "metadata": {},
   "source": [
    "## Task 2.4: Configure logging\n",
    "\n",
    "In this task, you set up logging to understand what your agent is doing behind the scenes. This helps you understand how the agent processes requests and uses tools.\n",
    "\n",
    "The Strands framework uses Python's standard logging module to provide visibility into agent operations. You can configure different log levels to get more or less detail about what your agent is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66415155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from strands import Agent\n",
    "import os\n",
    "\n",
    "# Enable detailed logging to understand what the agent is doing\n",
    "logging.getLogger(\"strands\").setLevel(logging.INFO)\n",
    "\n",
    "# Set up logging to write to both console and file\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Console output\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(\"agent_activity\")\n",
    "\n",
    "# Create an agent with logging enabled\n",
    "logger.info(\"Creating new agent with Nova Lite model\")\n",
    "logged_agent = Agent(callback_handler=None,model=\"amazon.nova-lite-v1:0\")\n",
    "\n",
    "logger.info(\"Sending message to agent: 'Hello! How are you?'\")\n",
    "response = logged_agent(\"Hello! How are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69e1a0",
   "metadata": {},
   "source": [
    "## Task 2.5: Explore model configuration\n",
    "\n",
    "In this task, you learn how to configure different models and settings for your agents. You can specify which AI model to use and adjust its behavior with parameters like temperature. Temperature controls how creative or consistent the responses are. Lower temperature values make responses more consistent and predictable, while higher values make them more creative and varied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13767dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# Create a custom model configuration\n",
    "custom_model = BedrockModel(\n",
    "    model_id=\"amazon.nova-lite-v1:0\",\n",
    "    temperature=0.3  # Lower temperature = more consistent responses\n",
    ")\n",
    "\n",
    "# Create an agent with the custom model\n",
    "custom_agent = Agent(callback_handler=None,model=custom_model)\n",
    "print(\"Agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ba1d7",
   "metadata": {},
   "source": [
    "## Task 2.6: Build a recipe assistant agent\n",
    "\n",
    "In this task, you create a more practical agent that can help with cooking. This recipe assistant can search the web for recipes and cooking information, showing how agents can be useful in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad2d9c3",
   "metadata": {},
   "source": [
    "First, install the web search package that your recipe agent needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ddgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff74b3f",
   "metadata": {},
   "source": [
    "Create a web search tool that your recipe agent can use to find cooking information and recipes online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580312ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent, tool\n",
    "from ddgs import DDGS\n",
    "from ddgs.exceptions import RatelimitException, DDGSException\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.getLogger(\"strands\").setLevel(logging.INFO)\n",
    "\n",
    "# Create a web search tool\n",
    "@tool\n",
    "def websearch(keywords: str, max_results: int = 3) -> str:\n",
    "    \"\"\"Search the web for information.\n",
    "    Args:\n",
    "        keywords (str): What to search for\n",
    "        max_results (int): How many results to return\n",
    "    Returns:\n",
    "        Search results as text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = DDGS().text(keywords, max_results=max_results)\n",
    "        return results if results else \"No results found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Search error: {e}\"\n",
    "\n",
    "print(\"Web search tool created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0560c754-md",
   "metadata": {},
   "source": [
    "Now create the recipe assistant agent that uses the web search tool to help with cooking questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the recipe assistant agent\n",
    "recipe_agent = Agent(callback_handler=None,\n",
    "    model=\"amazon.nova-lite-v1:0\",\n",
    "    system_prompt=\"\"\"You are RecipeBot, a helpful cooking assistant.\n",
    "    Help users find recipes and answer cooking questions.\n",
    "    Use the websearch tool to find recipes and cooking information.\"\"\",\n",
    "    tools=[websearch]\n",
    ")\n",
    "\n",
    "print(\"Recipe assistant agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6dafb2-md",
   "metadata": {},
   "source": [
    "Test your recipe assistant by asking it for cooking help. Watch how it uses the web search tool to find current information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6dafb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the recipe assistant\n",
    "response = recipe_agent(\"Suggest a simple recipe with chicken and broccoli.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f92c8a4",
   "metadata": {},
   "source": [
    "You have successfully created a practical AI agent that can search the web and help with cooking questions. This demonstrates how agents can be useful for real-world tasks.\n",
    "\n",
    "You have now experimented with the Strands Agents framework, which provides a way to build AI agents that can use tools and take actions. Using this framework, you have learned how agents differ from traditional LLMs by being able to actively use tools to accomplish tasks.\n",
    "\n",
    "### Try it yourself\n",
    "- Modify the system prompts to create agents for different use cases.\n",
    "- Create custom tools for specific tasks your team might need.\n",
    "- Experiment with different model configurations to understand how they affect agent behavior.\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file and continue with the **Conclusion**."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
